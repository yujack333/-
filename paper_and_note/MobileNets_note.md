## MobileNets

MobileNet是针对网络压缩提出来的，是希望将网络的参数和计算量都减少。在此基础上性能不会有太多的下降。
提出的方法是将传统的卷积操作进行分解。分解为两步：1.depthwise convolution(对feature map进行逐层的卷积) 
2.pointwise convolution(用N个1✖️1✖️M的卷积对第一步得到的feature map进行卷积得到N个feature map)

![](/pic/mobilenet.png)

下面来分析分解后的卷积操作在参数量和计算量上的减少情况：

- 参数量
  传统卷积的参数量为：![](/pic/m_p_0.gif) Dk为卷积核的大小，M为feature map的depth，N为有多少卷积核。
  
  分解后的第一步的参数量： ![](/pic/m_p_1.gif)
  
  分解后的第二步的参数量： ![](/pic/m_p_2.gif)
  
  分解后参数量占传统卷积的参数量的比例： ![](/pic/m_p_3.gif)
- 计算量
  传统卷积的计算量为：![](/pic/m_p_4.gif)
  
  分解后的第一步的计算量：![](/pic/m_p_5.gif)
  
  分解后的第二步的计算量：![](/pic/m_p_6.gif)
  
  分解后的计算量占传统卷积的计算量的比例：![](/pic/m_p_8.gif)
  
可以看到，卷积核的大小一般为3，也就是说：分解后的卷积操作比传统的卷积操作计算量小了8-9倍，参数量也小了8-9倍。

文章还介绍了两个来控制网络大小的参数：![](/pic/m_p_9.gif),第一个叫Width Multiplier，第二个叫Resolution Multiplier

第一个参数简单来说就是在原来网络的基础上，每层的输入feature map的channel和输出channel数量都减少。减少的系数就是这个参数。
第二个参数就是将输入图像的大小变小，变小的系数就是第二个参数。

这样做之后又可以进一步的控制模型的大小，这样可以很好的控制精度和模型大小的tradeoffs。

变换两个参数对性能的影响：

![](/pic/m_p_11.png)


文章只是通过分解卷积的方式来减少运算量和参数量，所以之前的一些网络结构还是可以用上的。文章中网络结构如下：

![](/pic/m_p_10.png)

文章方法在ImageNet、Dogs上的结果与其它网络的比较：

![](/pic/m_p_12.png)
