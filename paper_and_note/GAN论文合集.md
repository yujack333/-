* [1.GAN](#1)
* [2.DC-GAN](#2)
* [3.W-GAN](#3)
* [4.pix2pix](#4)
* [5.cycle-GAN](#5)
* [6.star-GAN](#6)

<h2 id="1">1.GAN</h2>

- [论文地址](https://arxiv.org/pdf/1406.2661.pdf)

------
### 总结
GAN模型包括了两个模块：
- 1.G：生成器。用来生成数据（这里的数据可以是图片，序列等等，这个生成模型生成的数据是为了拟合训练集数据里的分布）
- 2.D：判别器。用来判别生成器产生的数据是否符合训练集数据的分布（就像一个teacher）

G和D可以看成是相互竞争也可以看成是相互进步，他们在玩一个min max的游戏。G希望生成的数据可以让D认为符合训练集分布，
D希望可以判断出G生成的数据不符合训练集的分布。这样最后会达成一个纳什均衡，也就是说：G产生数据的分布和训练集的数据分布几乎一样，
而D无法判断一个数据是训练数据集的还是G产生的。

------
### 论文细节
- 1.loss function：

![](/pic/1.png)

- 2.loss function的一些问题

![](/pic/G_loss.png)

可以看出在早期，G产生的数据可以被D很容易的判断出来，这样导致![](/pic/GAN_2.png)(saturate),也就是说梯度消失导致G无法被训练。
所以可以将原先的最小化![](/pic/GAN_2.png)改为最大化![](/pic/GAN_3.png)。

- 3.GAN算法

算法步骤：

- 1.在G中生成m个样本
- 2.在真实数据中采样m个样本
- 3.利用这些样本来训练D
- 4.重复1-3 K次,训练一次
- 5.重复1-4 n次

![](/pic/GAN_algo.png)

-----
<h2 id="2">2.DC-GAN</h2>

- [论文地址](https://arxiv.org/pdf/1511.06434.pdf)

-----
### 总结

在GAN中使用卷积操作时会导致训练很不稳定，从而使得训练不成功。作者通过尝试不同的模型架构找到了一族架构，
这族架构可以设计很深且产生高分辨率的模型。这族架构在多个数据集上都可以训练出稳定的结果。

主要的架构上的改进为：
- 1.用全卷积。利用卷积中stride来down sample和up sample。让卷积自己去学习空间上的降采样和上采样。
- 2.移除全连接层
- 3.加batch normlization。生成器的输出层不加，判别器的输出层不加。
- 4.激活函数。生成器用relu，输出层用tanh。判别器用leacky relu。

-----
<h2 id="3">3.W-GAN</h2>

- [论文地址]（https://arxiv.org/pdf/1701.07875.pdf)

- [一个很好的总结](https://zhuanlan.zhihu.com/p/25071913)

-----
### 总结
原始的GAN的最大的问题就是训练不稳定。WGAN就GAN得训练不稳定给出了理论上的解释，并提出来新的loss来解决这个问题。
论文中提出：训练的不稳定主要是因为：当D训练得很好时G的loss不能很好的刻画生成数据集和真实数据集之间分布的距离。

原始GAN提出两种关于G的loss。
- 对于第一种loss：
如果D训练到最优。那么loss就等于![](/pic/WGAN1.png) 。其中JS为JS散度用来刻画两个分布之间的距离。问题就出现在这个JS散度上。
由于真实的分布和生成的分布几乎没有重叠的部分，或者说重叠的部分可以忽略不计。那么对于这样的两个分布而言，它们的JS散度为log2。
这就意味着loss无法衡量这两个分布的距离。因为loss恒为常数，所以梯度为0，导致无法训练生成器G。```总结来说：当D训练得太好的时候，
G几乎无法被优化。```

实验结果也印证了上述理论：

分别将DCGAN训练1，20，25个epoch，然后固定生成器不动，判别器随机初始化后重新训练。纵坐标为第一种loss下生成器的梯度大小。
可以看到随着判别器越来越好，生成器的梯度大小越来越小，趋近于0（消失）。

![](/pic/WGAN2.jpg)


- 对于第二种loss：
如果D训练到最优。那么loss就等价于![](/pic/WGAN4.png).其中KL和JS都为刻画两个分布距离的散度。这个等价最小化目标存在两个严重的问题。
第一是它需要同时最小化生成分布与真实分布之间的KL散度，同时又要最大化两者的JS散度，这在直观上是非常荒谬的，在数值上会导致梯度不稳定。
这是后面一项JS散度的问题。第二是KL散度也有问题，KL散度对于两类错的惩罚是不同的，对于生成的样本没有多样性的惩罚是微小的，对于生成了
不真实的样本的惩罚是巨大的。也就说在这样的惩罚下，生成器倾向于生成一些重复但“安全的样本”。也就是模型出现的collapse mode。

实验结果也印证了第二种loss会出现梯度不稳定的情况：

分别将DCGAN训练1，20，25个epoch，然后固定生成器不动，判别器随机初始化之后重新训练。纵坐标为第二种loss下生成器的梯度大小。
可以看到随着判别器越来越好，生成器的梯度越来越大，趋向于不稳定。

![](/pic/WGAN5.jpg)


wasserstein距离可以很好的刻画两个分布之间的距离，即使两个分布之间没有重叠的部分。W距离公式：![](/pic/WGAN6.png)
由于wasserstein距离中下界无法计算，所以经过一些估计和化简后整体模型的代价函数为：![](/pic/WGAN7.png)。
且其中的f(x)需要满足Lipschitz条件，为了达到这个要求，作者采取了一个简单的办法，将判别网络中的参数限制在【-c，c】之间。
生成器希望最小化这个代价函数（生成数据集和真实数据集竟可能的接近），判别器希望最大化这个代价函数（能很好的区分两个分布）。
所以，两个model的loss function如下：

![](/pic/WGAN8.png)

最后，通过上述的分析，我们给出最后的算法改进：
- 判别器最后一层的激活函数（sigmoid）去掉。
- 生成器和判别器的loss不取log
- 每次更新判别器的参数之后，将参数clip到[-c，c]之间。
- 不要用基于动量的优化算法。推荐RMSProp。

算法如下：

![](/pic/WGAN.jpg)


-------

<h2 id="4">4.pix2pix</h2>

- [论文地址](https://arxiv.org/pdf/1611.07004.pdf)

-------

### 总结

这篇论文是利用条件GAN做图像到图像的转换。这里的转换是将图像从一个域转换到另外一个域，在训练时图像要求成对的形式。
既有一张图片x就需要有一张转换后的图片y。而另一篇文章cycleGAN则不需要匹配的图像，就可以将一张图片转换到另外一个域。

### 论文细节

- 首先给出模型的架构：

![](/pic/pix1.png)

这里注意几点：
1.生成网络的输入仅仅为图片X，因为作者发现即使加入一个random noise - Z，生成模型也会倾向于忽视这个噪声。
2.判别网络的输入有两两张图，对于真实的样例而言就是上诉匹配的两张图片。对于假的样例而言，就是生成网络的输入和输出两张图片。

- 再来给出生成模型的架构：

![](/pic/pix2.png)

 这里生成网络用到的是U-net架构，设计的思想为：输入图像和输出图像在表现上是两张不同的图片，但就其实质而言是有相同的结构的。
 但是类似的encode decode网络架构中有bottleneck。这会导致输入图片的一些细节无法通过这个bottleneck而出现细节丢失。
 为了使这些细节能够绕过bottleneck，在网络中设置了skip connections。


- 判别模型的架构就和cGAN的思想一样，将x和y concat到一起，再送入网络中得到输出。

- 最后我们给出模型的loss：

![](/pic/pix3.png)

这里有一点小问题，D中应该还有一个变量x。可以看到除了GAN的loss外，生成器中还有一个额外的loss。这个loss描述的是
真实图像和生成图像之间pix的L1 loss。我们知道L1和L2范数loss产生的图像通常是模糊的，也就说它们可以抓住图像低频的
信息，而一些高频的信息比如边界，角点就很难捕捉到。所以在loss中加入L1范数模型在低频的方面做得更好。而为了使得判别器
在建模高频信息时表现更好，这里用到了patchGAN。


-------
<h2 id="5">5.cycle-GAN</h2>

- [论文地址](https://arxiv.org/pdf/1611.07004.pdf)

-------

### 总结
cycle-GAN是针对不匹配图片数据集之间的转换提出的。模型的输入有两个数据集X,Y。模型中包含两个生成器和两个判别器，生成器G是将图片数据集X中的图片转换到
图片数据集Y中，判别器D_Y则是判别生成的Y图像和真实的Y图像是否相似。生成器F则是将Y数据集里的图像转换到X数据集中，判别器D_X则是判别生成器F生成的图像和X
数据集中的真实图像是否相似。loss方面，除了adversarial loss之外，还有一个cycle consistency loss,这个loss是用来衡量经过生成器G,F循环重构出来的图像和真实图像的L1距离。

### 论文细节

- 生成器和判别器的架构：

![](/pic/cycle_network.png)

-  生成器：

生成器的网络架构可分为3个部分：1.降维编码：可以理解为提取源图像的特征。2.转换：可以理解为将源图像的特征转换到目标图像的特征。
3.升维解码：可以理解为将目标图像的特征解码为图像。降维是直接用卷积而没用池化，升维解码的最后一层用到的激活函数为tanh，这是
为了将输出信号转化到【-1，1】，再通过一个转化可以到【0，255】。在图像预处理阶段将图像转化到【-1，1】。

- 判别器：

判别器沿用DC-GAN的设计思想，用卷积来downsample。而且不会downsample到1 * 1，而是downsample到 16 * 16.这样可以稳定训练。最后一层卷积层不用
激活函数，标签为0，1，直接算最小二乘loss。这个ls-GAN提出的loss。也是可以解决原始GAN的一些问题。

- 整体的loss：

![](/pic/cycle_loss.png)

可以看到，整体的loss分为两个部分，一个是adversarial loss，一个是cycle consistency loss.判别器的loss中只有adversarial loss。生成器的loss
有这两个loss。

- cycle consistency loss

![](/pic/cycle_consistency_loss.png)

 可以看出是一个重构的loss，意思就是重构出来的图像要和源图像竟可能的接近。
 
- adversarial loss

![](/pic/cycle_ad_loss.png)

这里用的就是原始GAN论文中的loss。而实际中可以换成ls-gan，w-gan中的loss来稳定训练过程。

-------
<h2 id="5">5.cycle-GAN</h2>

- [论文地址](https://arxiv.org/pdf/1711.09020.pdf)

-------
### 总结
star-gan是针对多源图像转换提出来的一个模型，前面讲的cycle-gan只能进行两个数据集的相互转换，如果要做多源图像数据之间的转换将非常的困难。star-gan在这里只用到了一个生成器G和一个判别器D，生成器的输入有图像X和需要转换到的域的标签c，而判别器不仅仅需要判别图像的真假，还需要判别图像的类别。所以，对于G而言，loss分为三个部分。1.adver_loss 2.class_loss 3.reconstract_loss 。而D的loss分为两个部分:1.adver_loss 2. class_loss 。

### 论文细节

- 生成器和判别器的架构：

![](/pic/star-gan-network.png)

-  生成器：

生成器的网络架构可分为3个部分：1.降维编码：可以理解为提取源图像的特征。2.转换：可以理解为将源图像的特征转换到目标图像的特征。
3.升维解码：可以理解为将目标图像的特征解码为图像。降维是直接用卷积而没用池化，升维解码的最后一层用到的激活函数为tanh，这是
为了将输出信号转化到【-1，1】，再通过一个转化可以到【0，255】。在图像预处理阶段将图像转化到【-1，1】。
![](/pic/star-gan.png)

- 判别器：

判别器沿用DC-GAN的设计思想，用卷积来downsample。而且不会downsample到1 * 1，而是downsample到 16 * 16.这样可以稳定训练。最后一层由两个卷积操作得到两个输出，分别为判断真假的输出和判断类别的输出。
![](/pic/star-gan-D.png)

- 整体的loss：

![](/pic/star-gan-total_loss.png)



- reconstruction loss

![](/pic/star-gan-recon-loss.png)

 可以看出是一个重构的loss，先加条件c将图像转化到c域上，在加条件c'将图像转回来，这样重构出的图像要求与原图像的差别越小越好。
 
- classification loss

![](/pic/star-gan-fake-class-loss.png)

由G产生的图像需要让D认为它的类别为c

![](/pic/star-gan-real-class-loss.png)

D判别真实图像的类别的losss

- adversarial loss

![](/pic/star-gan-adver-loss.png)

